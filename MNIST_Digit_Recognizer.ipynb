{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Digit Recognizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Importing all the libraries**"
      ],
      "metadata": {
        "id": "14SkwPkIvmtM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "udW1JjF4vN72"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation, BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I658R16vTvN",
        "outputId": "44241265-322b-4eed-9d71-3746cbd9d288"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model**"
      ],
      "metadata": {
        "id": "p6NBiKAZwGlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **[LeNet-5] Modified Architecture**\n",
        "ConvNet --> ConvNet --> BatchNorm --> Pool --> (Dropout) --> ConvNet --> ConvNet --> BatchNorm --> Pool --> (Dropout) --> (Flatten) --> FullyConnected --> BatchNorm --> FullyConnected --> BatchNorm --> FullyConnected --> BatchNorm --> (Dropout) --> Softmax"
      ],
      "metadata": {
        "id": "FUuanLHX5Pue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LeNet5(input_shape = (32, 32, 1), classes = 10):\n",
        "    \"\"\"\n",
        "    Implementation of a modified LeNet-5.\n",
        "    Only those layers with learnable parameters are counted in the layer numbering.\n",
        "    \n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential([\n",
        "        \n",
        "    # Layer 1\n",
        "    Conv2D(filters = 32, kernel_size = 5, strides = 1, activation = 'relu', input_shape = (32,32,1), kernel_regularizer=l2(0.0005), name = 'convolution_1'),\n",
        "    \n",
        "    # Layer 2\n",
        "    Conv2D(filters = 32, kernel_size = 5, strides = 1, name = 'convolution_2', use_bias=False),\n",
        "    \n",
        "    # Layer 3    \n",
        "    BatchNormalization(name = 'batchnorm_1'),\n",
        "        \n",
        "    # -------------------------------- #  \n",
        "    Activation(\"relu\"),\n",
        "    MaxPooling2D(pool_size = 2, strides = 2, name = 'max_pool_1'),\n",
        "    Dropout(0.25, name = 'dropout_1'),\n",
        "    # -------------------------------- #  \n",
        "        \n",
        "    # Layer 3\n",
        "    Conv2D(filters = 64, kernel_size = 3, strides = 1, activation = 'relu', kernel_regularizer=l2(0.0005), name = 'convolution_3'),\n",
        "        \n",
        "    # Layer 4\n",
        "    Conv2D(filters = 64, kernel_size = 3, strides = 1, name = 'convolution_4', use_bias=False),\n",
        "        \n",
        "    # Layer 5\n",
        "    BatchNormalization(name = 'batchnorm_2'),\n",
        "        \n",
        "    # -------------------------------- #  \n",
        "    Activation(\"relu\"),\n",
        "    MaxPooling2D(pool_size = 2, strides = 2, name = 'max_pool_2'),\n",
        "    Dropout(0.25, name = 'dropout_2'),\n",
        "    Flatten(name = 'flatten'),\n",
        "    # -------------------------------- #  \n",
        "        \n",
        "    # Layer 6\n",
        "    Dense(units = 256, name = 'fully_connected_1', use_bias=False),\n",
        "        \n",
        "    # Layer 7\n",
        "    BatchNormalization(name = 'batchnorm_3'),\n",
        "    \n",
        "    # -------------------------------- #  \n",
        "    Activation(\"relu\"),\n",
        "    # -------------------------------- #  \n",
        "        \n",
        "    # Layer 8\n",
        "    Dense(units = 128, name = 'fully_connected_2', use_bias=False),\n",
        "        \n",
        "    # Layer 9\n",
        "    BatchNormalization(name = 'batchnorm_4'),\n",
        "        \n",
        "    # -------------------------------- #  \n",
        "    Activation(\"relu\"),\n",
        "    # -------------------------------- #  \n",
        "        \n",
        "    # Layer 10\n",
        "    Dense(units = 84, name = 'fully_connected_3', use_bias=False),\n",
        "        \n",
        "    # Layer 11\n",
        "    BatchNormalization(name = 'batchnorm_5'),\n",
        "        \n",
        "    # -------------------------------- #  \n",
        "    Activation(\"relu\"),\n",
        "    Dropout(0.25, name = 'dropout_3'),\n",
        "    # -------------------------------- #  \n",
        "\n",
        "    # Output\n",
        "    Dense(units = 10, activation = 'softmax', name = 'output')\n",
        "        \n",
        "    ])\n",
        "    \n",
        "    model._name = 'LeNet5'\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "0jLIOe-yv-vy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LeNet5Model = LeNet5(input_shape = (32, 32, 1), classes = 10)"
      ],
      "metadata": {
        "id": "utJf6LLRxhdl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LeNet5Model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ymsrqv0Gxl8v"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model Summary"
      ],
      "metadata": {
        "id": "mogdPZdoynC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LeNet5Model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny_q3OZkxvHE",
        "outputId": "5bb9e538-6be7-45f6-b5aa-5fe3190b8615"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"LeNet5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " convolution_1 (Conv2D)      (None, 28, 28, 32)        832       \n",
            "                                                                 \n",
            " convolution_2 (Conv2D)      (None, 24, 24, 32)        25600     \n",
            "                                                                 \n",
            " batchnorm_1 (BatchNormaliza  (None, 24, 24, 32)       128       \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " activation (Activation)     (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " max_pool_1 (MaxPooling2D)   (None, 12, 12, 32)        0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 12, 12, 32)        0         \n",
            "                                                                 \n",
            " convolution_3 (Conv2D)      (None, 10, 10, 64)        18496     \n",
            "                                                                 \n",
            " convolution_4 (Conv2D)      (None, 8, 8, 64)          36864     \n",
            "                                                                 \n",
            " batchnorm_2 (BatchNormaliza  (None, 8, 8, 64)         256       \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " max_pool_2 (MaxPooling2D)   (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " fully_connected_1 (Dense)   (None, 256)               262144    \n",
            "                                                                 \n",
            " batchnorm_3 (BatchNormaliza  (None, 256)              1024      \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " fully_connected_2 (Dense)   (None, 128)               32768     \n",
            "                                                                 \n",
            " batchnorm_4 (BatchNormaliza  (None, 128)              512       \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " fully_connected_3 (Dense)   (None, 84)                10752     \n",
            "                                                                 \n",
            " batchnorm_5 (BatchNormaliza  (None, 84)               336       \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 84)                0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 84)                0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 390,562\n",
            "Trainable params: 389,434\n",
            "Non-trainable params: 1,128\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Kaggle Data Processing**"
      ],
      "metadata": {
        "id": "Y3b_rsBg0dj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Upload Datasets"
      ],
      "metadata": {
        "id": "U9a6m0LTAYfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "fTdNacnQ4t3N",
        "outputId": "355257a4-6c82-4f1b-ed33-917ac958cbce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ae852481-f1ff-426b-9ed4-f9166f2c8c78\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ae852481-f1ff-426b-9ed4-f9166f2c8c78\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load Datasets"
      ],
      "metadata": {
        "id": "pQ1xNt0nAeDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "train = pd.read_csv(io.BytesIO(upload['train.csv']))\n",
        "test = pd.read_csv(io.BytesIO(upload['test.csv']))\n",
        "print(df)"
      ],
      "metadata": {
        "id": "6q6VOS18Aoyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "Y = train[['label']]\n",
        "X = train.drop(train.columns[[0]], axis=1)\n",
        "\n",
        "X = X.values.reshape(-1,28,28,1)\n",
        "test = test.values.reshape(-1,28,28,1)\n",
        "\n",
        "print(\"Size of Dataset: \" , len(X))\n",
        "\n",
        "cross_validation_size = int(len(X)*0.05)\n",
        "\n",
        "print(\"Size of Cross Validation Set: \" , cross_validation_size)\n",
        "\n",
        "random_seed = 2\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = cross_validation_size, random_state=random_seed)\n",
        "\n",
        "X_test = test\n",
        "\n",
        "plt.imshow(X_train[0][:,:,0])"
      ],
      "metadata": {
        "id": "mJ4PREC7yikW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "X_val = np.array(X_val)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Padding the images by 2 pixels since in the paper input images were 32x32\n",
        "X_train = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "X_val = np.pad(X_val, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "X_test = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "\n",
        "# Standardization\n",
        "mean_px = X_train.mean().astype(np.float32)\n",
        "std_px = X_train.std().astype(np.float32)\n",
        "X_train = (X_train - mean_px)/(std_px)\n",
        "\n",
        "mean_px = X_val.mean().astype(np.float32)\n",
        "std_px = X_val.std().astype(np.float32)\n",
        "X_val = (X_val - mean_px)/(std_px)\n",
        "\n",
        "mean_px = X_test.mean().astype(np.float32)\n",
        "std_px = X_test.std().astype(np.float32)\n",
        "X_test = (X_test - mean_px)/(std_px)\n",
        "\n",
        "# One-hot encoding the labels\n",
        "Y_train = to_categorical(Y_train, num_classes = 10)\n",
        "Y_val = to_categorical(Y_val, num_classes = 10)"
      ],
      "metadata": {
        "id": "t7zrDPRt0mrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# By using the image generator, we are not generating new data. We are only replacing the exisiting images. \n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center = False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center = False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization = False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization = False,  # divide each input by its std\n",
        "        zca_whitening = False,  # apply ZCA whitening\n",
        "        rotation_range = 10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range = 0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip = False,  # randomly flip images\n",
        "        vertical_flip = False)  # randomly flip images\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "IofGzaLp0qrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Variable Learning Rate**"
      ],
      "metadata": {
        "id": "AAEb5iMa0s_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variable_learning_rate = ReduceLROnPlateau(monitor='val_loss', factor = 0.2, patience = 2)"
      ],
      "metadata": {
        "id": "h1lqXbG_0wEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Model Training**\n"
      ],
      "metadata": {
        "id": "xOG2AFTe0zqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = LeNet5Model.fit(X_train, Y_train, epochs = 30, batch_size = 64, callbacks = [variable_learning_rate], validation_data=(X_val,Y_val))"
      ],
      "metadata": {
        "id": "HRPNIAfa1M8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training and Validation Accuracy Graph**"
      ],
      "metadata": {
        "id": "CtYOUSS_1mvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.figure()"
      ],
      "metadata": {
        "id": "1qhbxXM714zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Results**\n",
        "\n",
        "* **epochs - 30**\n",
        "\n",
        "* **loss - 0.0112**\n",
        "\n",
        "* **train_accuracy - 0.9982**\n",
        "\n",
        "* **val_loss - 0.0192**\n",
        "\n",
        "* **val_accuracy - 0.9962**\n",
        "\n",
        "* **Highest Dev Set Accuracy Obtained - 99.62%**\n"
      ],
      "metadata": {
        "id": "LnXt-cF25erW"
      }
    }
  ]
}